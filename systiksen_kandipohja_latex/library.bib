@misc{Kauranen,
	author = {Kauranen, I. and Mustakallio, M. and Palmgren, V.},
	title = {Tutkimusraportin kirjoittamisen opas opinnäytetyön tekijöille},
	publisher = {Teknillinen korkeakoulu},
	year = {2006},
	address = {Espoo}
},

@book{Itkonen,
	author = {Itkonen, M.},
	title = {Typografian käsikirja},
	publisher = {RPS-yhtiöt},
	year = {2007},
	address = {Helsinki}
},

@book{Koblitz,
	title={A course in number theory and cryptography},
	author={Koblitz, N.},
	volume={114},
	year={1994},
	publisher={Springer Science \& Business Media}
},

@article{bcs,
	title={Theory of superconductivity},
	author={Bardeen, J. and Cooper, {L.N.} and Schrieffer, {J.R.}},
	journal={Physical Review},
	volume={108},
	number={5},
	pages={1175--1204},
	year={1957},
	publisher={APS}
},

@article{Deschamps,
	title={Electromagnetics and differential forms},
	author={Deschamps, {G.A.}},
	journal={Proceedings of the IEEE},
	volume={69},
	number={6},
	pages={676--696},
	year={1981},
	publisher={IEEE}
},

@article{Sihvola,
	title={Interpretation of measurements of helix and bihelix superchiral structures},
	author={Sihvola, A. and Tretyakov, S. and Puska, P. and Kuehl, S.},
	journal={Bianisotropics'98},
	pages={317--320},
	year={1998}
},

@incollection{Lindblom,
	title={Tieteellisten opinn{\"a}ytet{\"o}iden ohjaaminen},
	author={Lindblom-Yl{\"a}nne, S. and Wager, M.},
	booktitle={Yliopisto- ja korkeakouluopettajan k{\"a}sikirja},
	editor={Lindblom-Yl{\"a}nne S. and Nevgi A.},
	publisher={WSOY},
	address={Helsinki},
	pages={314--325},
	year={2002}
},

@mastersthesis{Miinusmaa,
	title={Neliskulmaisen reiän poraamisesta kolmikulmaisella poralla},
	author={Miinusmaa, H.},
	school={Teknillinen korkeakoulu},
	type={Diplomityö},
	year={1977},
	address={Espoo}
},

@phdthesis{Loh,
	title={High-resolution micromachined interferometric accelerometer},
	author={Loh, {N.C.}},
	year={2001},
	school={Massachusetts Institute of Technology},
	address={Cambridge, MA}
},

@phdthesis{Lonnqvist,
	title={Applications of hologram-based compact range: antenna radiation pattern, radar cross section, and absorber reflectivity measurements},
	author={L{\"o}nnqvist, A.},
	year={2006},
	school={Teknillinen korkeakoulu},
	type={Väitöskirja},
	address={Espoo}
},

@misc{sfs,
	title={{SFS} 5342, Kirjallisuusviitteiden laatiminen},
	author={{Suomen standardisoimisliitto}},
	year={2004}
},

@misc{haastattelu,
	author={Palmgren, V.},
	title={{Suunnittelija. Teknillinen korkeakoulu, kirjasto. Otaniementie 9, 02150 Espoo. Haastattelu 15.1.}},
	year={2007}
},

@article{Ribeiro,
	title={Stochastic maximum-likelihood method for MIMO propagation parameter estimation},
	author={Ribeiro, {C.B.} and Ollila, E. and Koivunen, V.},
	journal={IEEE Transactions on Signal Processing},
	volume={55},
	number={1},
	pages={46--55},
	year={2006},
	publisher={IEEE}
},

@article{Stieber,
	title={GnuPG hacks},
	author={Stieber, T.},
	journal={Linux Journal},
	volume={143},
	pages={2},
	year={2006},
	publisher={Belltown Media}
},

@article{kone,
	title={Voiko kone tulevaisuudessa arvata tahtosi?},
	author={Pohjois-Koivisto, T.},
	journal={Apropos},
	month={Helmikuu},
	year={2005},
	note={Viitattu 19.1.2007.  Saatavissa: \url{http://www.apropos.fi/1-2005/prima.php}}
},

@article{Adida,
	title={Advances in cryptographic voting systems},
	author={Adida, B.},
	year={2006},
	journal={VTP Working Paper Series},
	volume={51},
	publisher={Caltech/MIT Voting Technology Project}
},

@article{viittaaminen,
	title={{WWW}-l{\"a}hteisiin viittaaminen tutkielmatekstiss{\"a}},
	author={Kilpel{\"a}inen, P},
	journal={Verkkodokumentti},
	year={2001},
	note={P{\"a}ivitetty 26.11.2001. Viitattu 19.1.2007. Saatavissa: \url{http://www.cs.uku.fi/~kilpelai/wwwlahteet.html}}
},

--------- Tästä alkaa omat lähteet ------------

@article{johnson2007,
    author = "Johnson, Valen E.",
    doi = "10.1214/07-BA229",
    fjournal = "Bayesian Analysis",
    journal = "Bayesian Anal.",
    month = "12",
    number = "4",
    pages = "719--733",
    publisher = "International Society for Bayesian Analysis",
    title = "Bayesian model assessment using pivotal quantities",
    url = "https://doi.org/10.1214/07-BA229",
    volume = "2",
    year = "2007"
},


@Article{Vehtari2017,
    author={Vehtari, Aki
    and Gelman, Andrew
    and Gabry, Jonah},
    title={Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC},
    journal={Statistics and Computing},
    year={2017},
    month={Sep},
    day={01},
    volume={27},
    number={5},
    pages={1413-1432},
    abstract={Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
    issn={1573-1375},
    doi={10.1007/s11222-016-9696-4},
    url={https://doi.org/10.1007/s11222-016-9696-4}
},


@Article{Piironen2017,
author={Piironen, Juho
	and Vehtari, Aki},
	title={Comparison of Bayesian predictive methods for model selection},
	journal={Statistics and Computing},
	year={2017},
	month={May},
	day={01},
	volume={27},
	number={3},
	pages={711-735},
	abstract={The goal of this paper is to compare several widely used Bayesian model selection methods in practical model selection problems, highlight their differences and give recommendations about the preferred approaches. We focus on the variable subset selection for regression and classification and perform several numerical experiments using both simulated and real world data. The results show that the optimization of a utility estimate such as the cross-validation (CV) score is liable to finding overfitted models due to relatively high variance in the utility estimates when the data is scarce. This can also lead to substantial selection induced bias and optimism in the performance evaluation for the selected model. From a predictive viewpoint, best results are obtained by accounting for model uncertainty by forming the full encompassing model, such as the Bayesian model averaging solution over the candidate models. If the encompassing model is too complex, it can be robustly simplified by the projection method, in which the information of the full model is projected onto the submodels. This approach is substantially less prone to overfitting than selection based on CV-score. Overall, the projection method appears to outperform also the maximum a posteriori model and the selection of the most probable variables. The study also demonstrates that the model selection can greatly benefit from using cross-validation outside the searching process both for guiding the model size selection and assessing the predictive performance of the finally selected model.},
	issn={1573-1375},
	doi={10.1007/s11222-016-9649-y},
	url={https://doi.org/10.1007/s11222-016-9649-y}
},

@Article{Gelman2014,
	author={Gelman, Andrew
	and Hwang, Jessica
	and Vehtari, Aki},
	title={Understanding predictive information criteria for Bayesian models},
	journal={Statistics and Computing},
	year={2014},
	month={Nov},
	day={01},
	volume={24},
	number={6},
	pages={997-1016},
	abstract={We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a bias-corrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this paper is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
	issn={1573-1375},
	doi={10.1007/s11222-013-9416-2},
	url={https://doi.org/10.1007/s11222-013-9416-2}
},


@article{Gneiting2011,
	author = {Tilmann Gneiting},
	title = {Making and Evaluating Point Forecasts},
	journal = {Journal of the American Statistical Association},
	volume = {106},
	number = {494},
	pages = {746-762},
	year  = {2011},
	publisher = {Taylor & Francis},
	doi = {10.1198/jasa.2011.r10138},
	URL = {https://doi.org/10.1198/jasa.2011.r10138},
	eprint = {https://doi.org/10.1198/jasa.2011.r10138}
},

@article{Prophet,
	title = {Forecasting at scale},
	author = {Taylor, Sean J and Letham, Benjamin},
	year = 2017,
	month = sep,
	keywords = {Time Series, Statistical Practice, Nonlinear Regression},
	abstract = {
		Forecasting is a common data science task that helps organizations with capacity planning, goal setting, and anomaly detection. Despite its importance, there are serious challenges associated with producing reliable and high quality forecasts — especially when there are a variety of time series and analysts with expertise in time series modeling are relatively rare. To address these challenges, we describe a practical approach to forecasting “at scale” that combines configurable models with analyst-in-the-loop performance analysis. We propose a modular regression model with interpretable parameters that can be intuitively adjusted by analysts with domain knowledge about the time series. We describe performance analyses to compare and evaluate forecasting procedures, and automatically flag forecasts for manual review and adjustment. Tools that help analysts to use their expertise most effectively enable reliable, practical forecasting of business time series.
		},
	volume = 5,
	pages = {e3190v2},
	journal = {PeerJ Preprints},
	issn = {2167-9843},
	url = {https://doi.org/10.7287/peerj.preprints.3190v2},
	doi = {10.7287/peerj.preprints.3190v2}
},

@article{vehtari2012,
	author = "Vehtari, Aki and Ojanen, Janne",
	doi = "10.1214/12-SS102",
	fjournal = "Statistics Surveys",
	journal = "Statist. Surv.",
	pages = "142--228",
	publisher = "The American Statistical Association, the Bernoulli Society, the Institute of Mathematical Statistics, and the Statistical Society of Canada",
	title = "A survey of Bayesian predictive methods for model assessment, selection and comparison",
	url = "https://doi.org/10.1214/12-SS102",
	volume = "6",
	year = "2012"
}

@article{10.5555/2567709.2502609,
	author = {Watanabe, Sumio},
	title = {A Widely Applicable Bayesian Information Criterion},
	year = {2013},
	issue_date = {January 2013},
	publisher = {JMLR.org},
	volume = {14},
	number = {1},
	issn = {1532-4435},
	abstract = {A statistical model or a learning machine is called regular if the map taking a parameter to a probability distribution is one-to-one and if its Fisher information matrix is always positive definite. If otherwise, it is called singular. In regular statistical models, the Bayes free energy, which is defined by the minus logarithm of Bayes marginal likelihood, can be asymptotically approximated by the Schwarz Bayes information criterion (BIC), whereas in singular models such approximation does not hold.Recently, it was proved that the Bayes free energy of a singular model is asymptotically given by a generalized formula using a birational invariant, the real log canonical threshold (RLCT), instead of half the number of parameters in BIC. Theoretical values of RLCTs in several statistical models are now being discovered based on algebraic geometrical methodology. However, it has been difficult to estimate the Bayes free energy using only training samples, because an RLCT depends on an unknown true distribution.In the present paper, we define a widely applicable Bayesian information criterion (WBIC) by the average log likelihood function over the posterior distribution with the inverse temperature 1/log n, where n is the number of training samples. We mathematically prove that WBIC has the same asymptotic expansion as the Bayes free energy, even if a statistical model is singular for or unrealizable by a statistical model. Since WBIC can be numerically calculated without any information about a true distribution, it is a generalized version of BIC onto singular statistical models.},
	journal = {J. Mach. Learn. Res.},
	month = mar,
	pages = {867–897},
	numpages = {31},
	keywords = {Bayes marginal likelihood, widely applicable Bayes information criterion}
}



http://users.jyu.fi/~hemipu/itms/Spiegelhalter%20et%20al.%202002%20JRSSb%20DIC.pdf
Bayesian measures of model complexity and fit


http://www.jmlr.org/papers/volume14/watanabe13a/watanabe13a.pdf
WAIC

http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf
WAIC asymptoottisuus

https://link-springer-com.libproxy.aalto.fi/content/pdf/10.1007/s11222-016-9696-4.pdf
PSIS
# Hemmetin hyviä plotteja, tästä inspistä

https://arxiv.org/pdf/1507.02646.pdf
PSIS kuvaus
# Vähän ohi aiheen, mutta plotti-inspiraatiota?

https://projecteuclid.org/download/pdfview_1/euclid.ssu/1356628931
Survey
# Aika jööti, mutta varmaan tapa osoittaa "industry standard" menetelmät


http://www.stat.columbia.edu/~gelman/research/published/bayes_R2_v3.pdf
R^2 bayeslaisille malleille


https://arxiv.org/pdf/1701.02434.pdf
HMC concept


https://arxiv.org/pdf/1111.4246.pdf
NUTS


https://arxiv.org/pdf/1604.00695.pdf
HMC disgnostiikka


https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2680310/pdf/nihms94914.pdf
Bayesian Variable Selection and Computation for GeneralizedLinear Models with Conjugate Priors
# Ei välttämättä just tähän, mut mahdollisesti hyvä lisä



